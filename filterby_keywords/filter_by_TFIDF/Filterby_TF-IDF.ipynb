{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf–idf is the product of two statistics, term frequency and inverse document frequency. There are various ways for determining the exact values of both statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score to be built in this part aims to define the importance of a keyword or phrase within a the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import argparse\n",
    "from configparser import ConfigParser\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MongoDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['secrets.ini']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ConfigParser()\n",
    "pardir = os.getcwd()\n",
    "config.read('secrets.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_USER = config['MONGODB']['CKIDS_USER']\n",
    "DB_PASS = config['MONGODB']['CKIDS_PASS']\n",
    "DB_NAME = config['MONGODB']['CKIDS_DB_NAME']\n",
    "HOST = config['AWS']['HOST_IP']\n",
    "PORT = config['AWS']['HOST_PORT']\n",
    "client = pymongo.MongoClient(\"mongodb://{DB_USER}:{DB_PASS}@{HOST}:{PORT}/{DB_NAME}\".format(\n",
    "    DB_USER=DB_USER, DB_PASS=DB_PASS, HOST=HOST, PORT=PORT, DB_NAME=DB_NAME))\n",
    "db = client[DB_NAME]\n",
    "collection = db[\"raw_artifacts\"]\n",
    "result = collection.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "objID_data = {}\n",
    "for obj in result:\n",
    "    description = obj['description']\n",
    "#     if description != '':\n",
    "#         description_data += [description]\n",
    "    try:\n",
    "        keywords = ' '.join(obj['keywords'])\n",
    "    except KeyError:\n",
    "        keywords = ''\n",
    "        None\n",
    "#     keywords_data += [keywords]    \n",
    "    title = obj['title']\n",
    "#     if title != '':\n",
    "#         title_data += [title]\n",
    "    objID_data[obj['_id']] = title+' '+description+' '+keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate TFIDF scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprocess keyword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_csv = pd.read_csv('final_kw_list.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_list = list(kw_csv[\"Other_word_to_match\"].str.split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term_list, documents):\n",
    "    \"\"\"\n",
    "    Calculate term frequency for 'term'.\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    term_list: the keyword to be evaluated, with options. np array, shape=(T, 2)\n",
    "    document: a document(here description paragraph string)\n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    a numerical frequency value.\n",
    "    \"\"\"\n",
    "    N, T = len(documents),len(term_list)\n",
    "    TF = np.zeros((N, T))\n",
    "    for j in range(N):\n",
    "        d = documents[j].lower()\n",
    "        for i in range(T):\n",
    "            word_options = term_list[i]\n",
    "            TF[j, i] = sum([d.count(w.lower()) for w in word_options])\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(TF):\n",
    "    \"\"\"\n",
    "    Calculate inverse document frequency for term wrt all documents.\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    TF: term frequency, numpy array (#documents, #terms)\n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    numpy array (#terms), numerical values of idfs\n",
    "    \"\"\"\n",
    "    N = TF.shape[0]\n",
    "    return np.log((277810-np.count_nonzero(TF, axis=0))/(1+np.count_nonzero(TF, axis=0)))\n",
    "# np.log(N/1+np.count_nonzero(TF, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TF = tf(term_list, list(objID_data.values()))\n",
    "\n",
    "IDF = idf(TF)\n",
    "\n",
    "TFIDF = TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Keyword':[t[0].strip(' ') for t in term_list], 'Term_frequency':TF.sum(axis=0),\n",
    "              'TFIDF_score':TFIDF.sum(axis=0), \n",
    "              'Log_TFIDF_score':np.log(TFIDF.sum(axis=0)+1)}).to_csv('final_kw_TFIDF_Score.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Relevance Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = pd.read_csv('final_kw_TFIDF_Score.csv', index_col=0)\n",
    "\n",
    "# kw_weights = dict(weight[['Keyword','TFIDF_score']].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_doc_scores = np.log(TF@(weight['TFIDF_score'].to_numpy())+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_scores_result = dict(zip([str(k) for k in objID_data.keys()],log_doc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose how many bins you want here\n",
    "num_bins = 20\n",
    "\n",
    "# Use the histogram function to bin the data\n",
    "counts, bin_edges = np.histogram(log_doc_scores, bins=num_bins)\n",
    "\n",
    "# Now find the cdf\n",
    "cdf = np.cumsum(counts)/len(log_doc_scores)\n",
    "\n",
    "# And finally plot the cdf\n",
    "plt.plot(bin_edges[1:], cdf)\n",
    "plt.xlabel('Relevance Score')\n",
    "plt.ylabel('cdf')\n",
    "plt.title(\"CDF of Relevance Score with {0} bins\".format(num_bins))\n",
    "plt.savefig('rlv_score_cdf.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('final_filter_TFIDF_result.json', 'w') as f:\n",
    "    json.dump(doc_scores_result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The web framework gets post_id from the URL and passes it as a string\n",
    "def get(post_id):\n",
    "    # Convert from string to ObjectId:\n",
    "    document = collection.find_one({'_id': ObjectId(post_id)})\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_words(l,j, term_list):\n",
    "    stf = {}\n",
    "    sample_data = []\n",
    "    terms = tf(term_list, objID_data[ObjectId(l)]).sum(axis=0)\n",
    "    stf = {}\n",
    "    for i in range(len(terms)):\n",
    "        if terms[i] > 0:\n",
    "            stf [term_list[i]] = int(terms[i])\n",
    "    sample_data += [['https://doi.org/'+get(l)['doi'], stf, np.log(j)]]\n",
    "    return sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_filter_TFIDF_result.json') as f:\n",
    "    doc_score_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277810"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_score_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169799 15650\n"
     ]
    }
   ],
   "source": [
    "ct0 = 0\n",
    "ct10 = 0\n",
    "for i, g in doc_score_data.items():\n",
    "    if g <= 0.1:\n",
    "        ct0 += 1\n",
    "    if g >= 13:\n",
    "        ct10 += 1\n",
    "print(ct0, ct10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yes = sorted(doc_score_data.items(), key=lambda x:x[1])[:-15650:-900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.choice(np.arange(15650), size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yy = []\n",
    "for y in yes:\n",
    "    yy += [[y[1], get(y[0])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5e60105b8fbee93a68d6b381', 17.13299310831989),\n",
       " ('5e6004ec6e9d3cc9bb4ab31d', 14.631959625111893),\n",
       " ('5e6004ff6e9d3cc9bb4abc3b', 14.417801335054381),\n",
       " ('5e60050f6e9d3cc9bb4ac4db', 14.236760805296022),\n",
       " ('5e6004f36e9d3cc9bb4ab429', 14.115099029216381),\n",
       " ('5e60122f8fbee93a68d75fc7', 13.934889090036513),\n",
       " ('5e6004846e9d3cc9bb4a83e6', 13.891955663182943),\n",
       " ('5e5ff9486e9d3cc9bb45f306', 13.740361446472235),\n",
       " ('5e600b839a1e02dbaa3d5669', 13.626563264121272),\n",
       " ('5e6004f36e9d3cc9bb4ab7ce', 13.60427389953237),\n",
       " ('5e6011288fbee93a68d7008f', 13.551487677586017),\n",
       " ('5e5ffc626e9d3cc9bb472a9d', 13.39391298065881),\n",
       " ('5e6005156e9d3cc9bb4acadc', 13.299618490423315),\n",
       " ('5e600bcb9a1e02dbaa3d7376', 13.227863522573822),\n",
       " ('5e60051f6e9d3cc9bb4accfc', 13.198809409026335),\n",
       " ('5e5fff436e9d3cc9bb485c15', 13.198809409026335),\n",
       " ('5e600d369a1e02dbaa3e0ca0', 13.157412679161403),\n",
       " ('5e60114a8fbee93a68d70e4f', 13.038659400219835)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.551487677586017,\n",
       " {'_id': ObjectId('5e6011288fbee93a68d7008f'),\n",
       "  'doi': '10.5281/zenodo.3497142',\n",
       "  'created': '2019-10-17T11:00:08.962973+00:00',\n",
       "  'files': [{'bucket': 'e97df660-b784-4fdb-8d6f-f044faf30fbf',\n",
       "    'checksum': 'md5:696257243152468ce045e58457492839',\n",
       "    'key': '9217ijcsit05.pdf',\n",
       "    'links': {'self': 'https://zenodo.org/api/files/e97df660-b784-4fdb-8d6f-f044faf30fbf/9217ijcsit05.pdf'},\n",
       "    'size': 246242,\n",
       "    'type': 'pdf'}],\n",
       "  'title': 'Image Encryption Techniques Using Fractal Function : A Review',\n",
       "  'creators': [{'affiliation': 'JSS Academy of Technical Education',\n",
       "    'name': 'Shafali Agarwal'}],\n",
       "  'description': '<p>An increasing demand of secure data transmission over internet leads to the challenge of implementing a consistent cryptosystem. In 2004, USA navy published the patent which highlights the importance of fractal as an encryption/decryption key in a cryptosystem [1]. Fractal possess butterfly effect i.e. sensitivity to initial condition, due to which small change in input produces a major change in output. This paper summarizes the various recent image encryption techniques in which fractal key is used to encrypt/decrypt followed by substitution, scrambling and diffusion techniques to provide strong cryptosystem. The algorithms covered both private key encryption as well as public key encryption technique in the paper. The analysed algorithms include a set of fractal function such as Mandelbrot set, Julia set, Hilbert curve, 3D fractal, multi-fractal, IFS and chaotic function to generate a complex key used in the encryption process. Corresponding performance of each algorithm is analysed by PSNR test, key space, sensitivity analysis and correlation coefficient value between the adjacent pixels of both images (Original image and encrypted image) which shows significant improvement in performance over the traditional encryption methods.</p>',\n",
       "  'keywords': ['Image Encryption', 'chaotic function', 'Scrambling'],\n",
       "  'resource_type': {'subtype': 'article',\n",
       "   'title': 'Journal article',\n",
       "   'type': 'publication'},\n",
       "  'tfidf_score': 15.277426958764506}]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "low0 = sorted(doc_score_data.items(), key=lambda x:x[1])[:10]\n",
    "low_n0 = sorted(doc_score_data.items(), key=lambda x:x[1])[ct0+11:ct0+21]\n",
    "middle = sorted(doc_score_data.items(), key=lambda x:x[1])[ct10+1:ct10+11]\n",
    "high = sorted(doc_score_data.items(), key=lambda x:x[1])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = []\n",
    "sdata = low0+low_n0+middle+high# \n",
    "\n",
    "for i in range(len(sdata)):\n",
    "    l, j = sdata[i]\n",
    "    stf = {}\n",
    "    for i in range(len(term_list)):\n",
    "        word_options = term_list[i]\n",
    "        d = objID_data[ObjectId(l)].lower()\n",
    "        fq = sum([d.count(w.lower()) for w in word_options])\n",
    "        if fq >=1 :\n",
    "            stf[term_list[i][0]] = fq    \n",
    "    sample_data += [['https://doi.org/'+get(l)['doi'], stf, j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = pd.DataFrame(sample_data, columns = ['url', 'term:frequency', 'log score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd['score category'] = ['zero']*10+['low']*10+['middle']*10+['high']*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>term:frequency</th>\n",
       "      <th>log score</th>\n",
       "      <th>score category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.3545811</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.3515458</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.3597391</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.344492</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1133037</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1314827</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.376969</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.177215</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1099416</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.16414</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1075741</td>\n",
       "      <td>{' TCAM ': 1}</td>\n",
       "      <td>4.481894</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.3490553</td>\n",
       "      <td>{' TCAM ': 1}</td>\n",
       "      <td>4.481894</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1322154</td>\n",
       "      <td>{' SHA-1 ': 1}</td>\n",
       "      <td>5.006854</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1322799</td>\n",
       "      <td>{' SHA-1 ': 1}</td>\n",
       "      <td>5.006854</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.569945</td>\n",
       "      <td>{'hash collision': 2}</td>\n",
       "      <td>5.019931</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://doi.org/10.3846/1648-0627.2008.9.33-44</td>\n",
       "      <td>{' ECB ': 1}</td>\n",
       "      <td>5.050251</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.2562967</td>\n",
       "      <td>{' ECB ': 1}</td>\n",
       "      <td>5.050251</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1194057</td>\n",
       "      <td>{'control-flow': 1}</td>\n",
       "      <td>5.094904</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.20030</td>\n",
       "      <td>{'control-flow': 1}</td>\n",
       "      <td>5.094904</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.322534</td>\n",
       "      <td>{' TCAM ': 2}</td>\n",
       "      <td>5.169369</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://doi.org/10.1080/17439884.2019.1573833</td>\n",
       "      <td>{'access control': 1, 'privacy': 1}</td>\n",
       "      <td>10.001952</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://doi.org/10.3897/JHR.46.6585.figure2</td>\n",
       "      <td>{'defense': 3}</td>\n",
       "      <td>10.004124</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1251917</td>\n",
       "      <td>{'defense': 3}</td>\n",
       "      <td>10.004124</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1251913</td>\n",
       "      <td>{'defense': 3}</td>\n",
       "      <td>10.004124</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1251908</td>\n",
       "      <td>{'defense': 3}</td>\n",
       "      <td>10.004124</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1251915</td>\n",
       "      <td>{'defense': 3}</td>\n",
       "      <td>10.004124</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1251899</td>\n",
       "      <td>{'defense': 3}</td>\n",
       "      <td>10.004124</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1251906</td>\n",
       "      <td>{'defense': 3}</td>\n",
       "      <td>10.004124</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1251901</td>\n",
       "      <td>{'defense': 3}</td>\n",
       "      <td>10.004124</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1251911</td>\n",
       "      <td>{'defense': 3}</td>\n",
       "      <td>10.004124</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.3554580</td>\n",
       "      <td>{'bug': 1, 'error-handling': 2, 'key': 85, 'pa...</td>\n",
       "      <td>16.051325</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>https://doi.org/10.5121/ijbb.2013.3104</td>\n",
       "      <td>{'Intrusion': 1, 'Network': 9, 'Risk': 2, 'Sec...</td>\n",
       "      <td>16.222024</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.3359666</td>\n",
       "      <td>{'Network': 1, 'Risk': 140, 'challenge': 1, 'n...</td>\n",
       "      <td>16.352652</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.35611</td>\n",
       "      <td>{'Network': 51, 'key': 3, 'network': 51}</td>\n",
       "      <td>16.459810</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.3489804</td>\n",
       "      <td>{'Risk': 163, 'Security': 2, 'Threat': 6, 'cha...</td>\n",
       "      <td>16.623287</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>https://doi.org/10.5121/ijbb.2013.3203</td>\n",
       "      <td>{'Network': 60, 'challenge': 1, 'key': 4, 'net...</td>\n",
       "      <td>16.629209</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.13881</td>\n",
       "      <td>{' IDS ': 2, 'Network': 88, 'Risk': 2, 'cipher...</td>\n",
       "      <td>16.992329</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://doi.org/10.5121/ijbb.2013.3202</td>\n",
       "      <td>{'Network': 96, 'defense': 1, 'key': 1, 'false...</td>\n",
       "      <td>17.083444</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>https://doi.org/10.5121/ijbb.2013.3302</td>\n",
       "      <td>{'Network': 96, 'challenge': 8, 'key': 2, 'net...</td>\n",
       "      <td>17.106165</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1162853</td>\n",
       "      <td>{'key': 264, 'verification': 20}</td>\n",
       "      <td>17.132993</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               url  \\\n",
       "0           https://doi.org/10.5281/zenodo.3545811   \n",
       "1           https://doi.org/10.5281/zenodo.3515458   \n",
       "2           https://doi.org/10.5281/zenodo.3597391   \n",
       "3            https://doi.org/10.5281/zenodo.344492   \n",
       "4           https://doi.org/10.5281/zenodo.1133037   \n",
       "5           https://doi.org/10.5281/zenodo.1314827   \n",
       "6            https://doi.org/10.5281/zenodo.376969   \n",
       "7            https://doi.org/10.5281/zenodo.177215   \n",
       "8           https://doi.org/10.5281/zenodo.1099416   \n",
       "9             https://doi.org/10.5281/zenodo.16414   \n",
       "10          https://doi.org/10.5281/zenodo.1075741   \n",
       "11          https://doi.org/10.5281/zenodo.3490553   \n",
       "12          https://doi.org/10.5281/zenodo.1322154   \n",
       "13          https://doi.org/10.5281/zenodo.1322799   \n",
       "14           https://doi.org/10.5281/zenodo.569945   \n",
       "15  https://doi.org/10.3846/1648-0627.2008.9.33-44   \n",
       "16          https://doi.org/10.5281/zenodo.2562967   \n",
       "17          https://doi.org/10.5281/zenodo.1194057   \n",
       "18            https://doi.org/10.5281/zenodo.20030   \n",
       "19           https://doi.org/10.5281/zenodo.322534   \n",
       "20   https://doi.org/10.1080/17439884.2019.1573833   \n",
       "21     https://doi.org/10.3897/JHR.46.6585.figure2   \n",
       "22          https://doi.org/10.5281/zenodo.1251917   \n",
       "23          https://doi.org/10.5281/zenodo.1251913   \n",
       "24          https://doi.org/10.5281/zenodo.1251908   \n",
       "25          https://doi.org/10.5281/zenodo.1251915   \n",
       "26          https://doi.org/10.5281/zenodo.1251899   \n",
       "27          https://doi.org/10.5281/zenodo.1251906   \n",
       "28          https://doi.org/10.5281/zenodo.1251901   \n",
       "29          https://doi.org/10.5281/zenodo.1251911   \n",
       "30          https://doi.org/10.5281/zenodo.3554580   \n",
       "31          https://doi.org/10.5121/ijbb.2013.3104   \n",
       "32          https://doi.org/10.5281/zenodo.3359666   \n",
       "33            https://doi.org/10.5281/zenodo.35611   \n",
       "34          https://doi.org/10.5281/zenodo.3489804   \n",
       "35          https://doi.org/10.5121/ijbb.2013.3203   \n",
       "36            https://doi.org/10.5281/zenodo.13881   \n",
       "37          https://doi.org/10.5121/ijbb.2013.3202   \n",
       "38          https://doi.org/10.5121/ijbb.2013.3302   \n",
       "39          https://doi.org/10.5281/zenodo.1162853   \n",
       "\n",
       "                                       term:frequency  log score  \\\n",
       "0                                                  {}   0.000000   \n",
       "1                                                  {}   0.000000   \n",
       "2                                                  {}   0.000000   \n",
       "3                                                  {}   0.000000   \n",
       "4                                                  {}   0.000000   \n",
       "5                                                  {}   0.000000   \n",
       "6                                                  {}   0.000000   \n",
       "7                                                  {}   0.000000   \n",
       "8                                                  {}   0.000000   \n",
       "9                                                  {}   0.000000   \n",
       "10                                      {' TCAM ': 1}   4.481894   \n",
       "11                                      {' TCAM ': 1}   4.481894   \n",
       "12                                     {' SHA-1 ': 1}   5.006854   \n",
       "13                                     {' SHA-1 ': 1}   5.006854   \n",
       "14                              {'hash collision': 2}   5.019931   \n",
       "15                                       {' ECB ': 1}   5.050251   \n",
       "16                                       {' ECB ': 1}   5.050251   \n",
       "17                                {'control-flow': 1}   5.094904   \n",
       "18                                {'control-flow': 1}   5.094904   \n",
       "19                                      {' TCAM ': 2}   5.169369   \n",
       "20                {'access control': 1, 'privacy': 1}  10.001952   \n",
       "21                                     {'defense': 3}  10.004124   \n",
       "22                                     {'defense': 3}  10.004124   \n",
       "23                                     {'defense': 3}  10.004124   \n",
       "24                                     {'defense': 3}  10.004124   \n",
       "25                                     {'defense': 3}  10.004124   \n",
       "26                                     {'defense': 3}  10.004124   \n",
       "27                                     {'defense': 3}  10.004124   \n",
       "28                                     {'defense': 3}  10.004124   \n",
       "29                                     {'defense': 3}  10.004124   \n",
       "30  {'bug': 1, 'error-handling': 2, 'key': 85, 'pa...  16.051325   \n",
       "31  {'Intrusion': 1, 'Network': 9, 'Risk': 2, 'Sec...  16.222024   \n",
       "32  {'Network': 1, 'Risk': 140, 'challenge': 1, 'n...  16.352652   \n",
       "33           {'Network': 51, 'key': 3, 'network': 51}  16.459810   \n",
       "34  {'Risk': 163, 'Security': 2, 'Threat': 6, 'cha...  16.623287   \n",
       "35  {'Network': 60, 'challenge': 1, 'key': 4, 'net...  16.629209   \n",
       "36  {' IDS ': 2, 'Network': 88, 'Risk': 2, 'cipher...  16.992329   \n",
       "37  {'Network': 96, 'defense': 1, 'key': 1, 'false...  17.083444   \n",
       "38  {'Network': 96, 'challenge': 8, 'key': 2, 'net...  17.106165   \n",
       "39                   {'key': 264, 'verification': 20}  17.132993   \n",
       "\n",
       "   score category  \n",
       "0            zero  \n",
       "1            zero  \n",
       "2            zero  \n",
       "3            zero  \n",
       "4            zero  \n",
       "5            zero  \n",
       "6            zero  \n",
       "7            zero  \n",
       "8            zero  \n",
       "9            zero  \n",
       "10            low  \n",
       "11            low  \n",
       "12            low  \n",
       "13            low  \n",
       "14            low  \n",
       "15            low  \n",
       "16            low  \n",
       "17            low  \n",
       "18            low  \n",
       "19            low  \n",
       "20         middle  \n",
       "21         middle  \n",
       "22         middle  \n",
       "23         middle  \n",
       "24         middle  \n",
       "25         middle  \n",
       "26         middle  \n",
       "27         middle  \n",
       "28         middle  \n",
       "29         middle  \n",
       "30           high  \n",
       "31           high  \n",
       "32           high  \n",
       "33           high  \n",
       "34           high  \n",
       "35           high  \n",
       "36           high  \n",
       "37           high  \n",
       "38           high  \n",
       "39           high  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.to_csv('final_samples_w_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrach Cells..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('keywords_for_TFIDF.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'worm' in x['Keywords'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Keywords\n",
       "71       and\n",
       "174       of\n",
       "175       on"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index_to_drop=[71, 174, 175]\n",
    "x.iloc[index_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(index=index_to_drop).reset_index(drop=True).to_csv('keywords_for_TFIDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_stale(term_list, documents):\n",
    "    \"\"\"\n",
    "    Calculate term frequency for 'term'.\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    term: the keyword to be evaluated.\n",
    "    document: a document(here description paragraph string)\n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    a numerical frequency value.\n",
    "    \"\"\"\n",
    "    N, T = len(documents), len(term_list)\n",
    "    TF = np.zeros((N, T))\n",
    "    for i in range(T):\n",
    "        for j in range(N):\n",
    "            # match both 'ab-cd' and 'ab cd'\n",
    "            if '-' in term_list[i]:\n",
    "                word = term_list[i].replace('-', ' ')\n",
    "                TF[j, i] = documents[j].lower().split().count(word.lower()) \\\n",
    "                            + documents[j].lower().split().count(term_list[i].lower())\n",
    "            else:\n",
    "                TF[j, i] = documents[j].lower().split().count(term_list[i].lower())\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf2_stale(term_list, documents):\n",
    "    \"\"\"\n",
    "    Calculate term frequency for 'term'.\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    term: the keyword to be evaluated.\n",
    "    document: a document(here description paragraph string)\n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    a numerical frequency value.\n",
    "    \"\"\"\n",
    "    N, T = len(documents), len(term_list)\n",
    "    TF = np.zeros((N, T))\n",
    "    for i in range(T):\n",
    "        for j in range(N):\n",
    "            d = documents[j].lower().split()\n",
    "            # match both 'ab-cd' and 'ab cd'\n",
    "            if '-' in term_list[i]:\n",
    "                word = term_list[i].replace('-', ' ')\n",
    "                TF[j, i] = d.count(word.lower()) \\\n",
    "                            + d.count(term_list[i].lower())\n",
    "            else:\n",
    "                TF[j, i] = d.count(term_list[i].lower())\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2280318"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834050"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612069"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834199"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for d in data:\n",
    "    if d == '':\n",
    "        data.remove(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keyword_data = pd.read_csv('v3_CKIDS_keywords_with_frequency.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def process_term_list(term_list):\n",
    "    term_list2 = []\n",
    "    for t in term_list:\n",
    "        if '-' in t:\n",
    "            term_list2 += [t, t.replace('-', ' ')]\n",
    "        if \"(\" and \")\" in t:\n",
    "            tt = t.split(\"(\")\n",
    "            if tt[0] == '':\n",
    "                term_list2 += [tt[1].replace(\")\",\"\")]\n",
    "            term_list2 += [tt[0].rstrip(\" \"), tt[1].replace(\")\",\"\")]\n",
    "        else:\n",
    "            term_list2 += [t]\n",
    "    return term_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term_list = process_term_list(keyword_data['Word'].unique())\n",
    "term_list = set(term_list)\n",
    "\n",
    "term_list.discard('')\n",
    "\n",
    "term_list = list(term_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.DataFrame(sorted(term_list), columns=['Keywords']).to_csv('keywords_for_TFIDF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some maunal process with plurals ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term_list = term_list.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tl = []\n",
    "for t in term_list:\n",
    "    tl += t.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tl_df = pd.DataFrame(sorted(tl), columns=['Keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tl = tl_df['Keywords'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.pop(tl, 'attacks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t in tl:\n",
    "     if t[-1] == 's':\n",
    "            print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(vocabulary=term_list, use_idf=False)\n",
    "#X = vectorizer.fit_transform(description_data)\n",
    "#X.todense().sum(axis=0)\n",
    "#pd.DataFrame({'Keyword':term_list, 'TFIDF_score':X.toarray().sum(axis=0)}).to_csv('kw_score_TFIDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrety SSL TLS decryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old--brush keywords list\n",
    "# keyword_data = pd.read_csv('v3_CKIDS_keywords_with_frequency.csv', index_col=0)\n",
    "# def process_term_list(term_list):\n",
    "#     term_list2 = []\n",
    "#     for t in term_list:\n",
    "#         # remove hyphens\n",
    "#         if '-' in t:\n",
    "#             term_list2 += [t.replace('-', ' ')]\n",
    "#         # separate terms with brackets\n",
    "#         elif \"(\" and \")\" in t:\n",
    "#             tt = t.split(\"(\")\n",
    "#             if tt[0] == '':\n",
    "#                 term_list2 += [tt[1].replace(\")\",\"\")]\n",
    "#             term_list2 += [tt[0].rstrip(\" \"), tt[1].replace(\")\",\"\")]\n",
    "#         else:\n",
    "#             term_list2 += [t]\n",
    "#     return term_list2\n",
    "# term_list = process_term_list(keyword_data['Word'].unique())\n",
    "# term_list = set(term_list)\n",
    "# term_list.discard('')\n",
    "# term_list = sorted(list(term_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = 0\n",
    "for i, g in data.items():\n",
    "    if g == 0:\n",
    "        ct += 1\n",
    "    elif g < 0:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_stale(term_list, documents):\n",
    "    \"\"\"\n",
    "    Calculate term frequency for 'term'.\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    term: the keyword to be evaluated.\n",
    "    document: a document(here description paragraph string)\n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    a numerical frequency value.\n",
    "    \"\"\"\n",
    "    N, T = len(documents), len(term_list)\n",
    "    TF = np.zeros((N, T))\n",
    "    for j in range(N):\n",
    "        d = documents[j].lower().split()\n",
    "        for i in range(T):\n",
    "            # match both 'ab-cd' and 'ab cd'\n",
    "            if '-' in term_list[i]:\n",
    "                word = term_list[i].replace('-', ' ')\n",
    "                TF[j, i] = d.count(word.lower()) \\\n",
    "                            + d.count(term_list[i].lower())\n",
    "            else:\n",
    "                TF[j, i] = d.count(term_list[i].lower())\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 21s, sys: 5.6 s, total: 7min 26s\n",
      "Wall time: 7min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filtered_obj = {}\n",
    "for objid, content in objID_data.items():\n",
    "    document = ' '.join(content)\n",
    "    filtered_obj[str(objid)] = calculate_doc_score(document, kw_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_doc_score_stale(document, kw_weights):\n",
    "    \"\"\"\n",
    "    document: str\n",
    "    kw_weights: dict\n",
    "    \"\"\"\n",
    "    relev_freq = []\n",
    "    d = document.lower().split()\n",
    "    for kw in kw_weights.keys():\n",
    "        if '-' in kw:\n",
    "            kw2 = kw.replace('-', ' ')\n",
    "            relev_freq += [d.count(kw.lower()) \\\n",
    "                        + d.count(kw2.lower())]\n",
    "        else:\n",
    "            relev_freq += [d.count(kw.lower())]\n",
    "    relev_score = np.dot(list(kw_weights.values()),relev_freq)\n",
    "    return relev_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
