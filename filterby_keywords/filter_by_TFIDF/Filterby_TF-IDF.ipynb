{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf–idf is the product of two statistics, term frequency and inverse document frequency. There are various ways for determining the exact values of both statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score to be built in this part aims to define the importance of a keyword or phrase within a the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import argparse\n",
    "from configparser import ConfigParser\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MongoDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParser()\n",
    "pardir = os.getcwd()\n",
    "config.read('secrets.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_USER = config['MONGODB']['CKIDS_USER']\n",
    "DB_PASS = config['MONGODB']['CKIDS_PASS']\n",
    "DB_NAME = config['MONGODB']['CKIDS_DB_NAME']\n",
    "HOST = config['AWS']['HOST_IP']\n",
    "PORT = config['AWS']['HOST_PORT']\n",
    "client = pymongo.MongoClient(\"mongodb://{DB_USER}:{DB_PASS}@{HOST}:{PORT}/{DB_NAME}\".format(\n",
    "    DB_USER=DB_USER, DB_PASS=DB_PASS, HOST=HOST, PORT=PORT, DB_NAME=DB_NAME))\n",
    "db = client[DB_NAME]\n",
    "collection = db[\"raw_artifacts\"]\n",
    "result = collection.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_data = []\n",
    "keywords_data = []\n",
    "title_data = []\n",
    "objID_data = {}\n",
    "for obj in result:\n",
    "    description = obj['description']\n",
    "    if description != '':\n",
    "        description_data += [description]\n",
    "        \n",
    "    try:\n",
    "        keywords = ' '.join(obj['keywords'])\n",
    "    except KeyError:\n",
    "        keywords = ''\n",
    "        None\n",
    "    keywords_data += [keywords]\n",
    "    \n",
    "    title = obj['title']\n",
    "    if title != '':\n",
    "        title_data += [title]\n",
    "        \n",
    "    objID_data[obj['_id']] = [title, description, keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = description_data + keywords_data + title_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate TFIDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_list = pd.read_csv('keywords_for_TFIDF.csv', index_col=0)['Keywords'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term_list, documents):\n",
    "    \"\"\"\n",
    "    Calculate term frequency for 'term'.\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    term: the keyword to be evaluated.\n",
    "    document: a document(here description paragraph string)\n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    a numerical frequency value.\n",
    "    \"\"\"\n",
    "    N, T = len(documents), len(term_list)\n",
    "    TF = np.zeros((N, T))\n",
    "    for j in range(N):\n",
    "        d = documents[j].lower().split()\n",
    "        for i in range(T):\n",
    "            # match both 'ab-cd' and 'ab cd'\n",
    "            if '-' in term_list[i]:\n",
    "                word = term_list[i].replace('-', ' ')\n",
    "                TF[j, i] = d.count(word.lower()) \\\n",
    "                            + d.count(term_list[i].lower())\n",
    "            else:\n",
    "                TF[j, i] = d.count(term_list[i].lower())\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(TF):\n",
    "    \"\"\"\n",
    "    Calculate inverse document frequency for term wrt all documents.\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    TF: term frequency, numpy array (#documents, #terms)\n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    numpy array (#terms), numerical values of idfs\n",
    "    \"\"\"\n",
    "    N = TF.shape[0]\n",
    "    return np.log(N/1+np.count_nonzero(TF, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = tf(term_list, data)\n",
    "\n",
    "IDF = idf(TF)\n",
    "\n",
    "TFIDF = TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Keyword':term_list, 'Term_frequency':TF.sum(axis=0),\n",
    "              'TFIDF_score':TFIDF.sum(axis=0)}).to_csv('kw_score_TF_TFIDF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Relevance Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = pd.read_csv('kw_score_TF_TFIDF.csv', index_col=0)\n",
    "\n",
    "kw_weights = dict(weight[['Keyword','TFIDF_score']].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_doc_score(document, kw_weights):\n",
    "    \"\"\"\n",
    "    document: str\n",
    "    kw_weights: dict\n",
    "    \"\"\"\n",
    "    relev_freq = []\n",
    "    d = document.lower().split()\n",
    "    for kw in kw_weights.keys():\n",
    "        if '-' in kw:\n",
    "            kw2 = kw.replace('-', ' ')\n",
    "            relev_freq += [d.count(kw.lower()) \\\n",
    "                        + d.count(kw2.lower())]\n",
    "        else:\n",
    "            relev_freq += [d.count(kw.lower())]\n",
    "    relev_score = np.dot(list(kw_weights.values()),relev_freq)\n",
    "    return relev_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834199"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(objID_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 21s, sys: 5.6 s, total: 7min 26s\n",
      "Wall time: 7min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filtered_obj = {}\n",
    "for objid, content in objID_data.items():\n",
    "    document = ' '.join(content)\n",
    "    filtered_obj[str(objid)] = calculate_doc_score(document, kw_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "d = np.array(list(filtered_obj.values()))\n",
    "\n",
    "# Choose how many bins you want here\n",
    "num_bins = 20\n",
    "\n",
    "# Use the histogram function to bin the data\n",
    "counts, bin_edges = np.histogram(d, bins=num_bins)\n",
    "\n",
    "# Now find the cdf\n",
    "cdf = np.cumsum(counts)\n",
    "\n",
    "# And finally plot the cdf\n",
    "plt.plot(bin_edges[1:], cdf)\n",
    "plt.xlabel('Relevance Score')\n",
    "plt.ylabel('cdf')\n",
    "plt.title(\"CDF of Relevance Score with {0} bins\".format(num_bins))\n",
    "plt.savefig('rlv_score_cdf.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('filter_TFIDF_result.json', 'w') as f:\n",
    "    json.dump(filtered_obj, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The web framework gets post_id from the URL and passes it as a string\n",
    "def get(post_id):\n",
    "    # Convert from string to ObjectId:\n",
    "    document = collection.find_one({'_id': ObjectId(post_id)})\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filter_TFIDF_result.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19293\n"
     ]
    }
   ],
   "source": [
    "ct0 = 0\n",
    "for i, g in data.items():\n",
    "    if g == 0:\n",
    "        ct0 += 1\n",
    "print(ct0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417099"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half = int(len(data)/2)\n",
    "half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "low0 = sorted(data.items(), key=lambda x:x[1])[:10]\n",
    "low_n0 = sorted(data.items(), key=lambda x:x[1])[ct0+1:ct0+11]\n",
    "middle = sorted(data.items(), key=lambda x:x[1])[half+1:half+11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in log\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "sample_data = []\n",
    "sdata = low0+low_n0+middle\n",
    "\n",
    "for i in range(len(sdata)):\n",
    "    l, j = sdata[i]\n",
    "    terms = tf(term_list, objID_data[ObjectId(l)]).sum(axis=0)\n",
    "    stf = {}\n",
    "    for i in range(len(terms)):\n",
    "        if terms[i] > 0:\n",
    "            stf [term_list[i]] = int(terms[i])\n",
    "    sample_data += [['https://doi.org/'+get(l)['doi'], stf, np.log(j)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = pd.DataFrame(sample_data, columns = ['url', 'term:frequency', 'log score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd['score category'] = ['zero']*10+['low']*10+['middle']*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>term:frequency</th>\n",
       "      <th>log score</th>\n",
       "      <th>score category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1467782</td>\n",
       "      <td>{}</td>\n",
       "      <td>-inf</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.893174</td>\n",
       "      <td>{}</td>\n",
       "      <td>-inf</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://doi.org/10.1515/crll.1866.66.92</td>\n",
       "      <td>{}</td>\n",
       "      <td>-inf</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.889276</td>\n",
       "      <td>{}</td>\n",
       "      <td>-inf</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.889177</td>\n",
       "      <td>{}</td>\n",
       "      <td>-inf</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://doi.org/10.1515/crll.1870.71.201</td>\n",
       "      <td>{}</td>\n",
       "      <td>-inf</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://doi.org/10.1163/187501799x00283</td>\n",
       "      <td>{}</td>\n",
       "      <td>-inf</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.3372103</td>\n",
       "      <td>{}</td>\n",
       "      <td>-inf</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://doi.org/10.1007/bf01826530</td>\n",
       "      <td>{}</td>\n",
       "      <td>-inf</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.889229</td>\n",
       "      <td>{}</td>\n",
       "      <td>-inf</td>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1004659</td>\n",
       "      <td>{'data-flow': 1}</td>\n",
       "      <td>7.178714</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1004659</td>\n",
       "      <td>{'data-flow': 1}</td>\n",
       "      <td>7.178714</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.3663579</td>\n",
       "      <td>{'oblivious': 1}</td>\n",
       "      <td>7.899566</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.3663579</td>\n",
       "      <td>{'oblivious': 1}</td>\n",
       "      <td>7.899566</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://doi.org/10.19238/andes2016</td>\n",
       "      <td>{'IDA': 1}</td>\n",
       "      <td>8.170717</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://doi.org/10.1086/212399</td>\n",
       "      <td>{'IDA': 1}</td>\n",
       "      <td>8.170717</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://doi.org/10.1086/251980</td>\n",
       "      <td>{'IDA': 1}</td>\n",
       "      <td>8.170717</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.2562070</td>\n",
       "      <td>{'IDA': 1}</td>\n",
       "      <td>8.170717</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://doi.org/10.1086/212018</td>\n",
       "      <td>{'IDA': 1}</td>\n",
       "      <td>8.170717</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://doi.org/10.1002/cber.19040370467</td>\n",
       "      <td>{'IDA': 1}</td>\n",
       "      <td>8.170717</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.164928</td>\n",
       "      <td>{'and': 5, 'mechanism': 1, 'model': 1, 'of': 4}</td>\n",
       "      <td>20.232097</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1490885</td>\n",
       "      <td>{'and': 5, 'of': 4, 'public': 4}</td>\n",
       "      <td>20.232121</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1490885</td>\n",
       "      <td>{'and': 5, 'of': 4, 'public': 4}</td>\n",
       "      <td>20.232121</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.2660686</td>\n",
       "      <td>{'analysis': 1, 'and': 2, 'of': 6, 'on': 1, 'p...</td>\n",
       "      <td>20.232143</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.2841866</td>\n",
       "      <td>{'analysis': 1, 'and': 5, 'authenticated': 1, ...</td>\n",
       "      <td>20.232144</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.2841866</td>\n",
       "      <td>{'analysis': 1, 'and': 5, 'authenticated': 1, ...</td>\n",
       "      <td>20.232144</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.2841866</td>\n",
       "      <td>{'analysis': 1, 'and': 5, 'authenticated': 1, ...</td>\n",
       "      <td>20.232144</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.2841866</td>\n",
       "      <td>{'analysis': 1, 'and': 5, 'authenticated': 1, ...</td>\n",
       "      <td>20.232144</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.1197517</td>\n",
       "      <td>{'and': 5, 'information': 1, 'of': 4, 'user': 1}</td>\n",
       "      <td>20.232156</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://doi.org/10.5281/zenodo.2542946</td>\n",
       "      <td>{'and': 7, 'data': 2, 'model': 1, 'of': 2, 'on...</td>\n",
       "      <td>20.232176</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         url  \\\n",
       "0     https://doi.org/10.5281/zenodo.1467782   \n",
       "1      https://doi.org/10.5281/zenodo.893174   \n",
       "2    https://doi.org/10.1515/crll.1866.66.92   \n",
       "3      https://doi.org/10.5281/zenodo.889276   \n",
       "4      https://doi.org/10.5281/zenodo.889177   \n",
       "5   https://doi.org/10.1515/crll.1870.71.201   \n",
       "6    https://doi.org/10.1163/187501799x00283   \n",
       "7     https://doi.org/10.5281/zenodo.3372103   \n",
       "8         https://doi.org/10.1007/bf01826530   \n",
       "9      https://doi.org/10.5281/zenodo.889229   \n",
       "10    https://doi.org/10.5281/zenodo.1004659   \n",
       "11    https://doi.org/10.5281/zenodo.1004659   \n",
       "12    https://doi.org/10.5281/zenodo.3663579   \n",
       "13    https://doi.org/10.5281/zenodo.3663579   \n",
       "14        https://doi.org/10.19238/andes2016   \n",
       "15            https://doi.org/10.1086/212399   \n",
       "16            https://doi.org/10.1086/251980   \n",
       "17    https://doi.org/10.5281/zenodo.2562070   \n",
       "18            https://doi.org/10.1086/212018   \n",
       "19  https://doi.org/10.1002/cber.19040370467   \n",
       "20     https://doi.org/10.5281/zenodo.164928   \n",
       "21    https://doi.org/10.5281/zenodo.1490885   \n",
       "22    https://doi.org/10.5281/zenodo.1490885   \n",
       "23    https://doi.org/10.5281/zenodo.2660686   \n",
       "24    https://doi.org/10.5281/zenodo.2841866   \n",
       "25    https://doi.org/10.5281/zenodo.2841866   \n",
       "26    https://doi.org/10.5281/zenodo.2841866   \n",
       "27    https://doi.org/10.5281/zenodo.2841866   \n",
       "28    https://doi.org/10.5281/zenodo.1197517   \n",
       "29    https://doi.org/10.5281/zenodo.2542946   \n",
       "\n",
       "                                       term:frequency  log score  \\\n",
       "0                                                  {}       -inf   \n",
       "1                                                  {}       -inf   \n",
       "2                                                  {}       -inf   \n",
       "3                                                  {}       -inf   \n",
       "4                                                  {}       -inf   \n",
       "5                                                  {}       -inf   \n",
       "6                                                  {}       -inf   \n",
       "7                                                  {}       -inf   \n",
       "8                                                  {}       -inf   \n",
       "9                                                  {}       -inf   \n",
       "10                                   {'data-flow': 1}   7.178714   \n",
       "11                                   {'data-flow': 1}   7.178714   \n",
       "12                                   {'oblivious': 1}   7.899566   \n",
       "13                                   {'oblivious': 1}   7.899566   \n",
       "14                                         {'IDA': 1}   8.170717   \n",
       "15                                         {'IDA': 1}   8.170717   \n",
       "16                                         {'IDA': 1}   8.170717   \n",
       "17                                         {'IDA': 1}   8.170717   \n",
       "18                                         {'IDA': 1}   8.170717   \n",
       "19                                         {'IDA': 1}   8.170717   \n",
       "20    {'and': 5, 'mechanism': 1, 'model': 1, 'of': 4}  20.232097   \n",
       "21                   {'and': 5, 'of': 4, 'public': 4}  20.232121   \n",
       "22                   {'and': 5, 'of': 4, 'public': 4}  20.232121   \n",
       "23  {'analysis': 1, 'and': 2, 'of': 6, 'on': 1, 'p...  20.232143   \n",
       "24  {'analysis': 1, 'and': 5, 'authenticated': 1, ...  20.232144   \n",
       "25  {'analysis': 1, 'and': 5, 'authenticated': 1, ...  20.232144   \n",
       "26  {'analysis': 1, 'and': 5, 'authenticated': 1, ...  20.232144   \n",
       "27  {'analysis': 1, 'and': 5, 'authenticated': 1, ...  20.232144   \n",
       "28   {'and': 5, 'information': 1, 'of': 4, 'user': 1}  20.232156   \n",
       "29  {'and': 7, 'data': 2, 'model': 1, 'of': 2, 'on...  20.232176   \n",
       "\n",
       "   score category  \n",
       "0            zero  \n",
       "1            zero  \n",
       "2            zero  \n",
       "3            zero  \n",
       "4            zero  \n",
       "5            zero  \n",
       "6            zero  \n",
       "7            zero  \n",
       "8            zero  \n",
       "9            zero  \n",
       "10            low  \n",
       "11            low  \n",
       "12            low  \n",
       "13            low  \n",
       "14            low  \n",
       "15            low  \n",
       "16            low  \n",
       "17            low  \n",
       "18            low  \n",
       "19            low  \n",
       "20         middle  \n",
       "21         middle  \n",
       "22         middle  \n",
       "23         middle  \n",
       "24         middle  \n",
       "25         middle  \n",
       "26         middle  \n",
       "27         middle  \n",
       "28         middle  \n",
       "29         middle  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.to_csv('samples_w_scores3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrach Cells..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_stale(term_list, documents):\n",
    "    \"\"\"\n",
    "    Calculate term frequency for 'term'.\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    term: the keyword to be evaluated.\n",
    "    document: a document(here description paragraph string)\n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    a numerical frequency value.\n",
    "    \"\"\"\n",
    "    N, T = len(documents), len(term_list)\n",
    "    TF = np.zeros((N, T))\n",
    "    for i in range(T):\n",
    "        for j in range(N):\n",
    "            # match both 'ab-cd' and 'ab cd'\n",
    "            if '-' in term_list[i]:\n",
    "                word = term_list[i].replace('-', ' ')\n",
    "                TF[j, i] = documents[j].lower().split().count(word.lower()) \\\n",
    "                            + documents[j].lower().split().count(term_list[i].lower())\n",
    "            else:\n",
    "                TF[j, i] = documents[j].lower().split().count(term_list[i].lower())\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf2_stale(term_list, documents):\n",
    "    \"\"\"\n",
    "    Calculate term frequency for 'term'.\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    term: the keyword to be evaluated.\n",
    "    document: a document(here description paragraph string)\n",
    "    \n",
    "    output:\n",
    "    -------\n",
    "    a numerical frequency value.\n",
    "    \"\"\"\n",
    "    N, T = len(documents), len(term_list)\n",
    "    TF = np.zeros((N, T))\n",
    "    for i in range(T):\n",
    "        for j in range(N):\n",
    "            d = documents[j].lower().split()\n",
    "            # match both 'ab-cd' and 'ab cd'\n",
    "            if '-' in term_list[i]:\n",
    "                word = term_list[i].replace('-', ' ')\n",
    "                TF[j, i] = d.count(word.lower()) \\\n",
    "                            + d.count(term_list[i].lower())\n",
    "            else:\n",
    "                TF[j, i] = d.count(term_list[i].lower())\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2280318"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834050"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612069"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834199"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for d in data:\n",
    "    if d == '':\n",
    "        data.remove(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keyword_data = pd.read_csv('v3_CKIDS_keywords_with_frequency.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def process_term_list(term_list):\n",
    "    term_list2 = []\n",
    "    for t in term_list:\n",
    "        if '-' in t:\n",
    "            term_list2 += [t, t.replace('-', ' ')]\n",
    "        if \"(\" and \")\" in t:\n",
    "            tt = t.split(\"(\")\n",
    "            if tt[0] == '':\n",
    "                term_list2 += [tt[1].replace(\")\",\"\")]\n",
    "            term_list2 += [tt[0].rstrip(\" \"), tt[1].replace(\")\",\"\")]\n",
    "        else:\n",
    "            term_list2 += [t]\n",
    "    return term_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term_list = process_term_list(keyword_data['Word'].unique())\n",
    "term_list = set(term_list)\n",
    "\n",
    "term_list.discard('')\n",
    "\n",
    "term_list = list(term_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.DataFrame(sorted(term_list), columns=['Keywords']).to_csv('keywords_for_TFIDF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some maunal process with plurals ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term_list = term_list.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tl = []\n",
    "for t in term_list:\n",
    "    tl += t.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tl_df = pd.DataFrame(sorted(tl), columns=['Keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tl = tl_df['Keywords'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.pop(tl, 'attacks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t in tl:\n",
    "     if t[-1] == 's':\n",
    "            print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(vocabulary=term_list, use_idf=False)\n",
    "#X = vectorizer.fit_transform(description_data)\n",
    "#X.todense().sum(axis=0)\n",
    "#pd.DataFrame({'Keyword':term_list, 'TFIDF_score':X.toarray().sum(axis=0)}).to_csv('kw_score_TFIDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrety SSL TLS decryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old--brush keywords list\n",
    "# keyword_data = pd.read_csv('v3_CKIDS_keywords_with_frequency.csv', index_col=0)\n",
    "# def process_term_list(term_list):\n",
    "#     term_list2 = []\n",
    "#     for t in term_list:\n",
    "#         # remove hyphens\n",
    "#         if '-' in t:\n",
    "#             term_list2 += [t.replace('-', ' ')]\n",
    "#         # separate terms with brackets\n",
    "#         elif \"(\" and \")\" in t:\n",
    "#             tt = t.split(\"(\")\n",
    "#             if tt[0] == '':\n",
    "#                 term_list2 += [tt[1].replace(\")\",\"\")]\n",
    "#             term_list2 += [tt[0].rstrip(\" \"), tt[1].replace(\")\",\"\")]\n",
    "#         else:\n",
    "#             term_list2 += [t]\n",
    "#     return term_list2\n",
    "# term_list = process_term_list(keyword_data['Word'].unique())\n",
    "# term_list = set(term_list)\n",
    "# term_list.discard('')\n",
    "# term_list = sorted(list(term_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = 0\n",
    "for i, g in data.items():\n",
    "    if g == 0:\n",
    "        ct += 1\n",
    "    elif g < 0:\n",
    "        print(i,j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
